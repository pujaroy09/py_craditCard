{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1 style=\"color: #6485DB;\">Problem Statement</h1>\n",
    "<hr>\n",
    "\n",
    "### Overview\n",
    "This is a regression problem where you need to predict the average spend of customers for the next 3 months.\n",
    "\n",
    "### Data Description\n",
    "**train.csv**<br>\n",
    "It contains the training data with advertisement details as described in the last section.\n",
    "\n",
    "**test.csv**<br>\n",
    "It has details of the customer for which we have to predict the spend for the next 3 months.\n",
    "\n",
    "**Data Dictionary**<br>\n",
    "The Data Dictionary is mentioned in detail in the file data_dictionary.xlsx.\n",
    "It contains information about the features of the dataset.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from catboost import CatBoostRegressor\n",
    "import xgboost as xgb\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder , StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_log_error as msle, r2_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description\n",
    "Let's first look at the data description."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_excel(\"data/Data_Dictionary.xlsx\", index_col = 0)\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/TRAIN.csv')\n",
    "test = pd.read_csv('data/TEST.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of data\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Describe the data to check central tendancies\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:**<br>\n",
    "We can notice that **Age column has some outliers** so we'll treat those values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the information about all the columns\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Treating NULL Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check for NULL values\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insights:**<br>\n",
    "1. Columns **`personal_loan_active`, `vehicle_loan_active`, `personal_loan_closed`, `vehicle_loan_closed`, `investment_1`, `investment_2`, `investment_3`, `investment_4`, `loan_enq`** have more than 90% null values, so we'll remove these features.\n",
    "\n",
    "2. For other columns with Null values, we will treat those with respective **'median'** values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropping unnecessary columns\n",
    "\n",
    "df.drop(columns=['personal_loan_active', 'vehicle_loan_active' ,'personal_loan_closed', 'vehicle_loan_closed','investment_1','investment_2','investment_3','investment_4','loan_enq'],axis=1,inplace=True)\n",
    "test.drop(columns=['personal_loan_active', 'vehicle_loan_active' ,'personal_loan_closed', 'vehicle_loan_closed','investment_1','investment_2','investment_3','investment_4','loan_enq'],axis=1,inplace=True)\n",
    "\n",
    "df.isnull().sum() # Checking for more columns with NULL values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# For the remaining columns with NULL values, we can impute them with respective median values\n",
    "\n",
    "df.fillna(df.median(), inplace=True)\n",
    "\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test.fillna(test.median(), inplace=True)\n",
    "\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Outliers treatment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the outliers in 'Age' column using boxplot\n",
    "plt.figure(figsize=(4,6))\n",
    "sns.boxplot(y=df['age'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As noticed in the boxplot, all values above 75 can be considered as outliers\n",
    "# So let's treat them with the median of 'Age' column\n",
    "\n",
    "df['age'] = np.where(df['age']>75, df['age'].median(), df['age'])\n",
    "test['age'] = np.where(test['age']>75, test['age'].median(), test['age'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check again for outliers in 'age' col.\n",
    "df['age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['age'].describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Let's visualize all the columns using boxplots to judge for outliers\n",
    "for col in df:\n",
    "    if (((df[col].dtype)=='float64') | ((df[col].dtype)=='int64')):\n",
    "        plt.figure(figsize=(3,3))\n",
    "        df.boxplot([col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# There might be many columns with outliers, let's treat them at once.\n",
    "\n",
    "# --- Train data ---\n",
    "def cap_data(data):\n",
    "    for col in data.columns:\n",
    "        if (((data[col].dtype)=='float64') | ((data[col].dtype)=='int64')):\n",
    "            percentiles = data[col].quantile([0.1,0.9]).values\n",
    "            data[col][data[col] <= percentiles[0]] = percentiles[0]\n",
    "            data[col][data[col] >= percentiles[1]] = percentiles[1]\n",
    "        else:\n",
    "            data[col]=data[col]\n",
    "    return data\n",
    "\n",
    "\n",
    "df = cap_data(df)\n",
    "test = cap_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender Ratio\n",
    "print(df['gender'].value_counts(normalize=True)*100)\n",
    "\n",
    "df['gender'].value_counts().plot.bar(cmap='summer')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:**<br>\n",
    "- The Male account holders are way too many than Females. With 85.7% and 14.3% respectively. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender vs Age Ratio\n",
    "plt.figure(figsize=(9,7))\n",
    "sns.countplot(df['age'],hue=df['gender'],data=df)\n",
    "plt.title(\"Gender vs Age Ratio\", fontsize=20)\n",
    "plt.xticks(rotation=65)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:**<br>\n",
    "- The gender column is Right Skewed.\n",
    "- Although there are a lot of Male counts than Females in each Age range, it seems that **there is a decrease in customer counts with increase in age.**\n",
    "- Pension age of 61 tends to have more customers than age range 50-60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the 'id' column from Test data\n",
    "ids = test['id']\n",
    "ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dividing the data\n",
    "X = df.drop(columns=['id','cc_cons','region_code'], axis=1)\n",
    "test = test.drop(columns=['id','region_code'], axis=1)\n",
    "\n",
    "y = df['cc_cons']\n",
    "\n",
    "X.shape, test.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "right_skewed_cols = ['debit_amount_apr','debit_amount_may',  'debit_amount_jun', \n",
    "                     'credit_amount_apr','credit_amount_may', 'credit_amount_jun']\n",
    "\n",
    "\n",
    "def log_transfrom(col, df):\n",
    "    \n",
    "    transformed_col = np.log1p(abs(df[col]))\n",
    "    #sns.distplot(transformed_col)\n",
    "    #plt.show()\n",
    "    \n",
    "    return transformed_col\n",
    "\n",
    "\n",
    "for col in right_skewed_cols:  \n",
    "    X[col] = log_transfrom(col, X)\n",
    "    test[col] = log_transfrom(col, test)\n",
    "print(X.shape, test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check the correlation between each column\n",
    "plt.figure(figsize=(30, 20))\n",
    "cols_corr = df.corr().abs()\n",
    "mask = np.zeros_like(cols_corr, dtype=np.bool)\n",
    "mask[np.triu_indices_from(mask)] = True\n",
    "sns.heatmap(cols_corr, linewidth=.02, vmin=0, vmax=1, cmap='summer', annot=True, mask = mask)\n",
    "plt.xticks(rotation=75)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Insight:**<br>\n",
    "- There are certain columns which have much higher correlation b/w them, We will have to eliminate the collinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upper = cols_corr.where(np.triu(np.ones(cols_corr.shape), k=1).astype(np.bool)) # selecting upper triangle of corr_matrix\n",
    "\n",
    "# Getting index of columns with correlation greater than 0.65 to drop them out\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.8)]\n",
    "to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns = to_drop, axis=1)\n",
    "\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate RMSLE score\n",
    "\n",
    "def rmsle(y_test, y_pred):\n",
    "    \n",
    "    sum=0.0\n",
    "    \n",
    "    for x,y in zip(y_test, y_pred):\n",
    "        \n",
    "        if x < 0 or y < 0:\n",
    "            continue\n",
    "        \n",
    "        p = np.log(y+1)\n",
    "        r = np.log(x+1)\n",
    "        sum += (p - r)**2\n",
    "    \n",
    "    return (sum / len(y_pred)) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Label Encoding\n",
    "Let's encode the categorical variables using LabelEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_cols = X.select_dtypes(include=['object']).columns.tolist()\n",
    "print(cat_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "for i in cat_cols:\n",
    "    X[i] = le.fit_transform(X[i]) # train data\n",
    "    test[i] = le.fit_transform(test[i]) # test data\n",
    "\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Standard Scaling\n",
    "Let's scale the numerical variables using StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_cols = [i for i in X.columns if i not in cat_cols]\n",
    "print(num_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "X[num_cols] = ss.fit_transform(X[num_cols])\n",
    "test[num_cols] = ss.fit_transform(test[num_cols])\n",
    "\n",
    "X.describe()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "mm = MinMaxScaler()\n",
    "X[num_cols] = mm.fit_transform(X[num_cols])\n",
    "test[num_cols] = mm.fit_transform(test[num_cols])\n",
    "\n",
    "print(X.shape, test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Train Test Split\n",
    "Let's split our training data into train and validation data needed to build our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(X, y,test_size=0.3,random_state=12)\n",
    "print(x_train.shape, x_val.shape, y_train.shape, y_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg = LinearRegression()\n",
    "rfreg = RandomForestRegressor()\n",
    "cbreg = CatBoostRegressor(iterations=100,\n",
    "                          learning_rate=0.1,\n",
    "                          eval_metric='MSLE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Fitting the models\n",
    "\n",
    "linreg.fit(x_train, y_train)\n",
    "rfreg.fit(x_train, y_train)\n",
    "cbreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make Predictions\n",
    "\n",
    "y_pred_linreg = linreg.predict(x_val)\n",
    "y_pred_rfreg = rfreg.predict(x_val)\n",
    "y_pred_cbreg = cbreg.predict(x_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for RMSLE scores\n",
    "print(\"RMSLE Scores:\\n\")\n",
    "print('LinearRegression:\\t', (msle(y_val, y_pred_linreg)*0.5)*100)\n",
    "print('RandomForestRegressor:\\t', (msle(y_val, y_pred_rfreg)*0.5)*100)\n",
    "print('CatBoostRegressor:\\t', (msle(y_val, y_pred_cbreg)*0.5)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Make Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Linear Regression\n",
    "final_pred = linreg.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()\n",
    "submission['id'] = ids.astype(int)\n",
    "submission['cc_cons'] = final_pred\n",
    "submission.to_csv('submission_linreg.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_pred2 = cbreg.predict(test)\n",
    "\n",
    "submission2 = pd.DataFrame()\n",
    "submission2['id'] = ids.astype(int)\n",
    "submission2['cc_cons'] = final_pred2\n",
    "submission2.to_csv('submission_cbreg.csv', index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
